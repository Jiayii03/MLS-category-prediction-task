{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having preprocessed the dataset, this notebook builds and trains an ANN, hopefully be able to classify transaction category and achieve decent result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Libraries\n",
    "\n",
    "I'll be using the PyTorch framework to build and train the ANN. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load & Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(258522, 111)\n",
      "[[ 2.15000183e-01  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  4.00000000e+00\n",
      "   2.90000000e+01  0.00000000e+00  0.00000000e+00 -1.21868499e-01\n",
      "  -1.20761722e-01  1.97299421e-02 -9.86674726e-02 -4.38451320e-01\n",
      "  -1.96335524e-01 -1.55773252e-01 -7.67301798e-01 -7.35667229e-01\n",
      "  -1.11007714e+00  1.19635329e-01 -7.43274093e-01  3.03134739e-01\n",
      "   4.27381575e-01 -1.39323413e-01 -3.96797895e-01  4.48687136e-01\n",
      "  -6.73760056e-01 -4.56344426e-01 -5.13957322e-01 -5.98248661e-01\n",
      "   3.68088007e-01 -5.38518801e-02  1.04132719e-01 -6.89168334e-01\n",
      "  -1.41409896e-02 -1.17392147e+00 -7.85798132e-02  8.00346583e-03\n",
      "  -4.28601593e-01 -6.50245667e-01  7.18181014e-01 -6.94372535e-01\n",
      "   1.40027106e-01 -4.61310267e-01  4.64503802e-02  9.86701906e-01\n",
      "  -2.60781109e-01 -8.11234191e-02 -1.72459960e-01 -2.04221606e-01\n",
      "  -1.66166008e-01  3.84134650e-01 -2.31410652e-01 -5.04765809e-01\n",
      "  -3.08833510e-01  1.29452646e-01  5.55279136e-01  1.06327973e-01\n",
      "   2.55392671e-01 -6.91788644e-02  5.17179191e-01 -4.14870948e-01\n",
      "   1.33644059e-01 -6.57483995e-01  5.48318148e-01 -6.65316209e-02\n",
      "  -1.37011446e-02  2.56179422e-02  2.54411668e-01  6.12802088e-01\n",
      "  -2.85688221e-01  4.42719430e-01 -1.43343031e-01  1.93069652e-01\n",
      "   4.53442276e-01  6.35174751e-01 -7.79609531e-02  3.13000888e-01\n",
      "   7.25438535e-01  3.34390163e-01 -7.61588216e-01 -4.97100413e-01\n",
      "  -2.04721987e-01 -4.94532734e-02  7.12031484e-01 -6.39229640e-02\n",
      "   2.91168272e-01  1.18107545e+00 -2.83911884e-01 -2.22606838e-01\n",
      "   1.27257794e-01  3.62065345e-01  2.72354364e-01 -8.84659886e-01\n",
      "  -2.30154321e-01 -4.22999620e-01  5.70765018e-01  6.35811269e-01\n",
      "   2.88373977e-02  5.50189354e-02  8.89996067e-02 -2.34730676e-01\n",
      "   2.03703105e-01 -2.67911553e-01  6.23061419e-01 -3.92602146e-01\n",
      "  -2.54376411e-01 -1.69966370e-03  3.90468359e-01]\n",
      " [ 2.76603359e-01  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   1.40000000e+01  0.00000000e+00  0.00000000e+00 -3.15883726e-01\n",
      "   1.00511789e-01  1.36999935e-02 -2.95775831e-02  3.65632549e-02\n",
      "  -2.44015083e-01 -7.79285192e-01 -7.65126646e-01 -4.75925863e-01\n",
      "  -9.36203539e-01  1.98341548e-01 -7.86616385e-01  1.98992133e-01\n",
      "   4.25180882e-01 -9.41753685e-02 -6.63713634e-01  4.68182504e-01\n",
      "  -7.76644349e-02 -4.39784557e-01 -3.89660150e-01 -3.11753482e-01\n",
      "   6.16932102e-02 -3.48695606e-01 -1.40425880e-02  9.43570212e-02\n",
      "  -3.78535330e-01 -9.82954025e-01  1.37720257e-01  2.47686580e-01\n",
      "  -3.05121392e-01 -5.23319840e-01  3.12046021e-01 -9.92185324e-02\n",
      "  -2.95258146e-02 -2.26427987e-01  3.25621247e-01  3.73213500e-01\n",
      "  -9.41602811e-02  1.22676138e-03 -4.11324650e-02 -5.15318334e-01\n",
      "  -9.65218842e-02  1.13288447e-01 -7.97566921e-02 -4.81010750e-02\n",
      "  -6.00844800e-01 -9.14031118e-02  1.17381044e-01  1.52300224e-01\n",
      "   3.43504995e-01 -1.28613785e-01  3.82481188e-01 -1.29429907e-01\n",
      "   4.16809432e-02 -4.66676563e-01  5.81288524e-02 -5.00419617e-01\n",
      "   1.20468765e-01 -4.60899621e-02  5.37014604e-01  8.35451007e-01\n",
      "  -2.90193200e-01  7.91911900e-01 -4.39137995e-01 -4.01024111e-02\n",
      "  -1.09626047e-01  1.19998395e-01 -2.85040557e-01  3.60984147e-01\n",
      "   2.95863420e-01  3.21654409e-01 -4.56118822e-01 -3.23960841e-01\n",
      "  -4.25586671e-01 -3.61523405e-02  5.34845650e-01  6.04570769e-02\n",
      "   3.82631682e-02  8.48950267e-01 -6.02778271e-02  1.04167219e-02\n",
      "  -2.63946414e-01  4.50413942e-01 -1.04977503e-01 -5.37054479e-01\n",
      "  -5.18551245e-02 -2.19340116e-01  2.68958688e-01  1.59438193e-01\n",
      "   3.31067979e-01 -2.43079066e-02 -1.40792876e-01 -1.99142933e-01\n",
      "   3.34558606e-01  3.97921860e-01  4.29614753e-01 -6.65836409e-02\n",
      "  -1.70522094e-01 -9.00781248e-04  2.42015705e-01]\n",
      " [ 2.15000183e-01  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   2.50000000e+01  0.00000000e+00  0.00000000e+00  8.80614296e-02\n",
      "  -1.10207098e-02  1.29361898e-01 -5.16032934e-01 -3.64766151e-01\n",
      "  -2.18516827e-01 -3.36172074e-01 -8.72736156e-01 -5.77910244e-01\n",
      "  -1.13584769e+00  3.23268682e-01 -3.83597702e-01  1.50526300e-01\n",
      "   4.60441977e-01 -4.66638841e-02 -1.79585740e-01 -7.19219148e-02\n",
      "  -2.32831880e-01 -2.36148145e-02 -4.58453208e-01 -1.87684372e-01\n",
      "   2.37207472e-01 -3.46975207e-01 -1.47525951e-01 -2.13663220e-01\n",
      "  -1.77015975e-01 -7.79921234e-01  8.39391351e-02  1.41932055e-01\n",
      "  -1.47540346e-01 -4.01550889e-01  4.63005543e-01 -1.72326863e-01\n",
      "   2.95599494e-02 -9.00007412e-02  6.47334531e-02  5.68813980e-01\n",
      "  -2.28337228e-01 -1.28998205e-01 -1.95242509e-01 -1.53888002e-01\n",
      "  -2.34067783e-01  3.18858325e-01 -8.29850286e-02  2.61987627e-01\n",
      "  -7.92229950e-01 -3.15647602e-01  4.47315902e-01 -5.41864894e-02\n",
      "   3.98055643e-01 -1.97513893e-01  1.87030807e-01  4.74282593e-01\n",
      "   1.12979859e-03 -4.91722316e-01  3.50277185e-01 -1.41421229e-01\n",
      "  -2.92190816e-02 -3.94803621e-02  2.86590934e-01  6.18085086e-01\n",
      "  -5.33802748e-01  6.98074818e-01 -3.60793948e-01  1.20832592e-01\n",
      "   6.65829107e-02 -1.47410156e-02 -5.29195189e-01  4.18842047e-01\n",
      "   1.69538841e-01  3.15084564e-03 -4.58187312e-01 -4.23335820e-01\n",
      "  -2.04963997e-01  1.36496410e-01  3.80363196e-01  1.42530620e-01\n",
      "   2.61349082e-01  1.11073422e+00 -1.52026080e-02  7.80880079e-02\n",
      "  -3.58380228e-01 -1.50721297e-01  1.60609454e-01 -6.05926692e-01\n",
      "  -2.75843114e-01 -2.46032372e-01  4.00399655e-01  4.15895909e-01\n",
      "   2.17985347e-01  1.55519232e-01 -7.27673471e-02 -1.75103292e-01\n",
      "   1.88108489e-01  7.85812289e-02  3.85640532e-01 -7.13469684e-02\n",
      "  -2.79082537e-01 -5.46101443e-02  2.94503748e-01]\n",
      " [ 1.65717643e-01  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  4.00000000e+00\n",
      "   2.00000000e+00  0.00000000e+00  0.00000000e+00 -3.42665732e-01\n",
      "   1.11858860e-01 -4.76848707e-03 -5.58100581e-01  1.43209815e-01\n",
      "  -2.88522482e-01 -1.00556862e+00 -9.66224790e-01 -7.65120089e-01\n",
      "  -1.24582338e+00  2.12875456e-01 -9.51037526e-01 -3.23038511e-02\n",
      "   5.74890912e-01 -9.77172256e-02 -9.42462683e-01  7.05415010e-01\n",
      "  -3.78195524e-01 -7.45735407e-01 -5.68726063e-01 -1.93501681e-01\n",
      "  -2.03979611e-02 -5.12530446e-01  8.52935314e-02  1.61596015e-01\n",
      "  -4.25014913e-01 -1.26828337e+00  1.29253775e-01 -3.01516056e-03\n",
      "  -1.90185070e-01 -8.15905690e-01  4.18250471e-01  1.69223011e-01\n",
      "   1.44259214e-01 -1.92679301e-01  5.22539854e-01  5.69186747e-01\n",
      "  -1.21933758e-01 -1.55447096e-01  1.30404338e-01 -7.81411946e-01\n",
      "   4.62388992e-03  3.49389017e-01  1.82102844e-01  6.09337211e-01\n",
      "  -1.19711721e+00  1.60403550e-03  2.65966624e-01  5.90355873e-01\n",
      "   6.11723661e-01 -1.60846829e-01  5.37129104e-01 -1.38589978e-01\n",
      "   1.36708856e-01 -4.65091586e-01 -1.75277218e-02 -5.75310528e-01\n",
      "   3.09729129e-01 -9.75003242e-02  9.27793801e-01  1.37681985e+00\n",
      "  -3.51434708e-01  1.15078175e+00 -7.03806758e-01 -1.70067459e-01\n",
      "  -1.54523641e-01  1.01103194e-01 -6.76732063e-01  5.88682592e-01\n",
      "   2.25838721e-01  5.43786287e-01 -6.02081299e-01 -4.58173096e-01\n",
      "  -3.56102645e-01 -2.13430613e-01  8.70752454e-01 -2.86032315e-02\n",
      "   2.08521962e-01  1.39968324e+00 -1.02424681e-01  1.31687894e-01\n",
      "  -5.56300104e-01  1.74930066e-01 -1.17450982e-01 -1.02060974e+00\n",
      "  -2.07494810e-01  1.02743477e-01  2.97623247e-01  1.62717551e-01\n",
      "   3.67757946e-01 -1.44994855e-01 -3.04231435e-01 -2.51778245e-01\n",
      "   5.46415389e-01  5.33012211e-01  5.44437766e-01 -2.93768764e-01\n",
      "  -2.73413211e-03 -2.56382614e-01  5.70888706e-02]\n",
      " [ 1.78700202e-02  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  3.00000000e+00\n",
      "   1.00000000e+00  0.00000000e+00  0.00000000e+00 -3.42665732e-01\n",
      "   1.11858860e-01 -4.76848707e-03 -5.58100581e-01  1.43209815e-01\n",
      "  -2.88522482e-01 -1.00556862e+00 -9.66224790e-01 -7.65120089e-01\n",
      "  -1.24582338e+00  2.12875456e-01 -9.51037526e-01 -3.23038511e-02\n",
      "   5.74890912e-01 -9.77172256e-02 -9.42462683e-01  7.05415010e-01\n",
      "  -3.78195524e-01 -7.45735407e-01 -5.68726063e-01 -1.93501681e-01\n",
      "  -2.03979611e-02 -5.12530446e-01  8.52935314e-02  1.61596015e-01\n",
      "  -4.25014913e-01 -1.26828337e+00  1.29253775e-01 -3.01516056e-03\n",
      "  -1.90185070e-01 -8.15905690e-01  4.18250471e-01  1.69223011e-01\n",
      "   1.44259214e-01 -1.92679301e-01  5.22539854e-01  5.69186747e-01\n",
      "  -1.21933758e-01 -1.55447096e-01  1.30404338e-01 -7.81411946e-01\n",
      "   4.62388992e-03  3.49389017e-01  1.82102844e-01  6.09337211e-01\n",
      "  -1.19711721e+00  1.60403550e-03  2.65966624e-01  5.90355873e-01\n",
      "   6.11723661e-01 -1.60846829e-01  5.37129104e-01 -1.38589978e-01\n",
      "   1.36708856e-01 -4.65091586e-01 -1.75277218e-02 -5.75310528e-01\n",
      "   3.09729129e-01 -9.75003242e-02  9.27793801e-01  1.37681985e+00\n",
      "  -3.51434708e-01  1.15078175e+00 -7.03806758e-01 -1.70067459e-01\n",
      "  -1.54523641e-01  1.01103194e-01 -6.76732063e-01  5.88682592e-01\n",
      "   2.25838721e-01  5.43786287e-01 -6.02081299e-01 -4.58173096e-01\n",
      "  -3.56102645e-01 -2.13430613e-01  8.70752454e-01 -2.86032315e-02\n",
      "   2.08521962e-01  1.39968324e+00 -1.02424681e-01  1.31687894e-01\n",
      "  -5.56300104e-01  1.74930066e-01 -1.17450982e-01 -1.02060974e+00\n",
      "  -2.07494810e-01  1.02743477e-01  2.97623247e-01  1.62717551e-01\n",
      "   3.67757946e-01 -1.44994855e-01 -3.04231435e-01 -2.51778245e-01\n",
      "   5.46415389e-01  5.33012211e-01  5.44437766e-01 -2.93768764e-01\n",
      "  -2.73413211e-03 -2.56382614e-01  5.70888706e-02]]\n"
     ]
    }
   ],
   "source": [
    "# Load the preprocessed data\n",
    "df = pd.read_csv(\"../dataset/clean_embedding_bank_transaction.csv\")\n",
    "\n",
    "# Extract all feature columns that are not prefixed with \"category_\"\n",
    "feature_columns = [col for col in df.columns if not col.startswith(\"category_\")]\n",
    "X = df[feature_columns].values\n",
    "print(X.shape)\n",
    "print(X[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(258522, 33)\n",
      "[[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "# Extract all category columns\n",
    "y = df.filter(like=\"category_\").values \n",
    "print(y.shape)\n",
    "print(y[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train: torch.Size([180965, 111])\n",
      "Shape of X_test: torch.Size([77557, 111])\n",
      "Shape of y_train: torch.Size([180965, 33])\n",
      "Shape of y_test: torch.Size([77557, 33])\n"
     ]
    }
   ],
   "source": [
    "# Train-test split (80/20)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Normalize features using z-score normalization\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Apply the scaler to specific columns 7 - 9, ['day_of_week', 'day_of_month', 'hour']\n",
    "X_train[:, 7:10] = scaler.fit_transform(X_train[:, 7:10])\n",
    "X_test[:, 7:10] = scaler.transform(X_test[:, 7:10])\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32)  # Use float for BCE loss\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float32)\n",
    "\n",
    "# Create DataLoaders\n",
    "batch_size = 32\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, drop_last=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, drop_last=True)\n",
    "\n",
    "# Print dataset shapes\n",
    "print(\"Shape of X_train:\", X_train_tensor.shape)\n",
    "print(\"Shape of X_test:\", X_test_tensor.shape)\n",
    "print(\"Shape of y_train:\", y_train_tensor.shape)\n",
    "print(\"Shape of y_test:\", y_test_tensor.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the ANN Architecture\n",
    "\n",
    "Since this is a multi-class classification problem (one-hot encoded category labels):\n",
    "\n",
    "- Use fully connected layers\n",
    "- Apply Batch Normalization for stable training\n",
    "- Use Dropout to prevent overfitting\n",
    "- Use Sigmoid activation at the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the ANN model\n",
    "class TransactionClassifier(nn.Module):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super(TransactionClassifier, self).__init__()\n",
    "        \n",
    "        self.fc1 = nn.Linear(input_size, 256)  # First hidden layer\n",
    "        self.bn1 = nn.BatchNorm1d(256)  # Batch normalization\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.dropout1 = nn.Dropout(0.3)\n",
    "        \n",
    "        self.fc2 = nn.Linear(256, 128)  # Second hidden layer\n",
    "        self.bn2 = nn.BatchNorm1d(128)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.dropout2 = nn.Dropout(0.3)\n",
    "\n",
    "        self.fc3 = nn.Linear(128, num_classes)  # Output layer\n",
    "        self.sigmoid = nn.Sigmoid()  # Sigmoid activation for multi-label classification\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.dropout1(x)\n",
    "\n",
    "        x = self.fc2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.dropout2(x)\n",
    "\n",
    "        x = self.fc3(x)\n",
    "        x = self.sigmoid(x)  # Sigmoid for multi-label output\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialise the Model\n",
    "\n",
    "- Use binary cross-entropy for multi-class classification\n",
    "- Use Adam optimiser with learning rate 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TransactionClassifier(\n",
      "  (fc1): Linear(in_features=111, out_features=256, bias=True)\n",
      "  (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU()\n",
      "  (dropout1): Dropout(p=0.3, inplace=False)\n",
      "  (fc2): Linear(in_features=256, out_features=128, bias=True)\n",
      "  (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU()\n",
      "  (dropout2): Dropout(p=0.3, inplace=False)\n",
      "  (fc3): Linear(in_features=128, out_features=33, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Set device (GPU if available)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Define input size and output size\n",
    "input_size = X_train.shape[1]  # Total number of input features\n",
    "num_classes = y_train.shape[1]  # Number of one-hot encoded categories\n",
    "\n",
    "# Initialize the model\n",
    "model = TransactionClassifier(input_size, num_classes).to(device)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "loss_fn = nn.BCELoss()  \n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Print model summary\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Train Test Function\n",
    "\n",
    "- Train the model for an epoch.\n",
    "- Evaluate the model on the test set after each epoch.\n",
    "- Print Train Accuracy, Train Loss, Test Accuracy, and Test Loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# Function to train and evaluate the model\n",
    "def train_and_evaluate(model, train_loader, test_loader, loss_fn, optimizer, num_epochs=20, device=\"cpu\"):\n",
    "    model.to(device)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_train_loss = 0.0\n",
    "        correct_train = 0\n",
    "        total_train = 0\n",
    "\n",
    "        train_progress = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs} [Training]\", leave=False)\n",
    "        for batch_X, batch_y in train_progress:\n",
    "            batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(batch_X)\n",
    "            loss = loss_fn(outputs, batch_y)\n",
    "\n",
    "            # Backward pass\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Compute loss\n",
    "            running_train_loss += loss.item()\n",
    "\n",
    "            # Compute instance-level accuracy\n",
    "            predicted_classes = torch.argmax(outputs, dim=1)  # Predicted category index\n",
    "            true_classes = torch.argmax(batch_y, dim=1)  # Actual category index\n",
    "            correct_train += (predicted_classes == true_classes).sum().item()\n",
    "            total_train += batch_y.size(0)  # Number of transactions\n",
    "\n",
    "            train_progress.set_postfix(loss=loss.item())\n",
    "\n",
    "        avg_train_loss = running_train_loss / len(train_loader)\n",
    "        train_accuracy = correct_train / total_train\n",
    "\n",
    "        # Evaluation phase\n",
    "        model.eval()\n",
    "        running_test_loss = 0.0\n",
    "        correct_test = 0\n",
    "        total_test = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            test_progress = tqdm(test_loader, desc=f\"Epoch {epoch+1}/{num_epochs} [Evaluating]\", leave=False)\n",
    "            for batch_X, batch_y in test_progress:\n",
    "                batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "\n",
    "                outputs = model(batch_X)\n",
    "                loss = loss_fn(outputs, batch_y)\n",
    "                running_test_loss += loss.item()\n",
    "\n",
    "                # Compute instance-level accuracy\n",
    "                predicted_classes = torch.argmax(outputs, dim=1)\n",
    "                true_classes = torch.argmax(batch_y, dim=1)\n",
    "                correct_test += (predicted_classes == true_classes).sum().item()\n",
    "                total_test += batch_y.size(0)\n",
    "\n",
    "                test_progress.set_postfix(loss=loss.item())\n",
    "\n",
    "        avg_test_loss = running_test_loss / len(test_loader)\n",
    "        test_accuracy = correct_test / total_test\n",
    "\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}] - Train Loss: {avg_train_loss:.4f}, Train Acc: {train_accuracy:.4f}, \"\n",
    "              f\"Test Loss: {avg_test_loss:.4f}, Test Acc: {test_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train and Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20] - Train Loss: 0.0528, Train Acc: 0.6727, Test Loss: 0.0377, Test Acc: 0.7400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/20] - Train Loss: 0.0408, Train Acc: 0.7322, Test Loss: 0.0338, Test Acc: 0.7749\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/20] - Train Loss: 0.0387, Train Acc: 0.7467, Test Loss: 0.0323, Test Acc: 0.7864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/20] - Train Loss: 0.0374, Train Acc: 0.7562, Test Loss: 0.0314, Test Acc: 0.7950\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/20] - Train Loss: 0.0364, Train Acc: 0.7626, Test Loss: 0.0304, Test Acc: 0.7958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/20] - Train Loss: 0.0359, Train Acc: 0.7664, Test Loss: 0.0303, Test Acc: 0.7957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/20] - Train Loss: 0.0353, Train Acc: 0.7708, Test Loss: 0.0307, Test Acc: 0.7888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/20] - Train Loss: 0.0348, Train Acc: 0.7738, Test Loss: 0.0294, Test Acc: 0.8074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/20] - Train Loss: 0.0345, Train Acc: 0.7747, Test Loss: 0.0292, Test Acc: 0.8003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/20] - Train Loss: 0.0344, Train Acc: 0.7765, Test Loss: 0.0296, Test Acc: 0.7936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/20] - Train Loss: 0.0340, Train Acc: 0.7786, Test Loss: 0.0283, Test Acc: 0.8097\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/20] - Train Loss: 0.0337, Train Acc: 0.7805, Test Loss: 0.0289, Test Acc: 0.7999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/20] - Train Loss: 0.0336, Train Acc: 0.7816, Test Loss: 0.0278, Test Acc: 0.8119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/20] - Train Loss: 0.0334, Train Acc: 0.7827, Test Loss: 0.0293, Test Acc: 0.7974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/20] - Train Loss: 0.0331, Train Acc: 0.7850, Test Loss: 0.0283, Test Acc: 0.8080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/20] - Train Loss: 0.0331, Train Acc: 0.7849, Test Loss: 0.0283, Test Acc: 0.8029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/20] - Train Loss: 0.0329, Train Acc: 0.7854, Test Loss: 0.0277, Test Acc: 0.8138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/20] - Train Loss: 0.0327, Train Acc: 0.7865, Test Loss: 0.0284, Test Acc: 0.8006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/20] - Train Loss: 0.0327, Train Acc: 0.7875, Test Loss: 0.0277, Test Acc: 0.8088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/20] - Train Loss: 0.0327, Train Acc: 0.7876, Test Loss: 0.0276, Test Acc: 0.8153\n",
      "Training and evaluation complete!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "# Train and evaluate the model\n",
    "train_and_evaluate(model, train_loader, test_loader, loss_fn, optimizer, num_epochs=20, device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "torch.save(model.state_dict(), \"../models/ANN_20e_1e-3lr_4l_classifier.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict Categories for Random Test Instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to predict categories for test instances\n",
    "def predict_random_test_samples(model, X_test_tensor, y_test_tensor, label_encoder, num_samples=5, device=\"cpu\"):\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    X_test_tensor = X_test_tensor.to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # Select random samples from the test set\n",
    "        indices = np.random.choice(len(X_test_tensor), num_samples, replace=False)\n",
    "        X_samples = X_test_tensor[indices]\n",
    "        y_samples = y_test_tensor[indices]\n",
    "\n",
    "        # Get model predictions\n",
    "        outputs = model(X_samples)\n",
    "        predicted_classes = torch.argmax(outputs, dim=1).cpu().numpy()  # Convert to category index\n",
    "        true_classes = torch.argmax(y_samples, dim=1).cpu().numpy()  # Convert ground truth to category index\n",
    "\n",
    "        # Convert indices to category labels\n",
    "        predicted_labels = label_encoder.inverse_transform(predicted_classes)\n",
    "        true_labels = label_encoder.inverse_transform(true_classes)\n",
    "\n",
    "        # Print results\n",
    "        print(\"\\n===== Model Predictions vs. Ground Truth =====\")\n",
    "        for i in range(num_samples):\n",
    "            print(f\"Test Instance {i+1}:\")\n",
    "            print(f\"  ➤ Predicted Category: {predicted_labels[i]}\")\n",
    "            print(f\"  ➤ Ground Truth:      {true_labels[i]}\")\n",
    "            print(\"---------------------------------------------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Model Predictions vs. Ground Truth =====\n",
      "Test Instance 1:\n",
      "  ➤ Predicted Category: category_Digital Entertainment\n",
      "  ➤ Ground Truth:      category_Digital Entertainment\n",
      "---------------------------------------------------\n",
      "Test Instance 2:\n",
      "  ➤ Predicted Category: category_Transfer Credit\n",
      "  ➤ Ground Truth:      category_Transfer Credit\n",
      "---------------------------------------------------\n",
      "Test Instance 3:\n",
      "  ➤ Predicted Category: category_Convenience Stores\n",
      "  ➤ Ground Truth:      category_Convenience Stores\n",
      "---------------------------------------------------\n",
      "Test Instance 4:\n",
      "  ➤ Predicted Category: category_Arts and Entertainment\n",
      "  ➤ Ground Truth:      category_Arts and Entertainment\n",
      "---------------------------------------------------\n",
      "Test Instance 5:\n",
      "  ➤ Predicted Category: category_Supermarkets and Groceries\n",
      "  ➤ Ground Truth:      category_Uncategorized\n",
      "---------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Extract category column names dynamically\n",
    "category_columns = [col for col in df.columns if col.startswith(\"category_\")]\n",
    "\n",
    "# Create label encoder based on column order\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(category_columns) \n",
    "\n",
    "# Call the function to predict & compare results\n",
    "predict_random_test_samples(model, X_test_tensor, y_test_tensor, label_encoder, num_samples=5, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
